#  _____                          
# |_   _|____  ____ _ _ __   ___  
#   | |/ _ \ \/ / _` | '_ \ / _ \ 
#   | | (_) >  < (_| | | | | (_) |
#   |_|\___/_/\_\__,_|_| |_|\___/ 
#                              
# meta banner: https://envs.sh/rjm.jpg
# meta developer: @Toxano_Modules
# scope: @Toxano_Modules
import logging
import aiohttp
import asyncio
from telethon.tl.types import Message
from typing import List, Dict, Union
from .. import loader, utils

logger = logging.getLogger(__name__)

@loader.tds
class OpenRouterAIMod(loader.Module):
    """Advanced AI chat module using OpenRouter API with multiple models support"""

    strings = {
        "name": "Ai",
        "no_api_key": "‚ö†Ô∏è <b>Please set your OpenRouter API key first using .aiconfig</b>",
        "api_key_set": "‚úÖ <b>API key set successfully!</b>",
        "processing": "ü§î <b>Processing your request...</b>",
        "error_processing": "‚ùå <b>Error processing request:</b> <code>{}</code>",
        "no_response": "‚ùå <b>No response from AI</b>",
        "history_cleared": "üóë <b>Chat history cleared!</b>",
        "model_set": "‚úÖ <b>AI model set to:</b> <code>{}</code>",
        "role_set": "‚úÖ <b>AI role set to:</b> <code>{}</code>",
        "current_settings": "‚öôÔ∏è <b>Current Settings:</b>\n\n<b>Model:</b> <code>{model}</code>\n<b>Role:</b> <code>{role}</code>",
        "available_models": "üìã <b>Available Models:</b>\n\n{}"
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            "API_KEY",
            "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",
            "OpenRouter API Key",
            "DEFAULT_MODEL",
            "google/gemma-3-27b-it",
            "Default AI Model",
            "DEFAULT_ROLE",
            "You are a helpful AI assistant",
            "Default AI Role",
        )
        self.chat_history = {}
        self.models = {
            "qwen/qwen3-235b-a22b:free": "Qwen 235B",         
            "google/gemma-3-27b-it:free": "Gemma 27B",
            "deepseek/deepseek-r1:free": "DeepSeek R1",
            "deepseek/deepseek-prover-v2:free": "DeepSeek Chat V3"
        }

    async def client_ready(self):
        """Called when client is ready"""
        self.current_model = self.config["DEFAULT_MODEL"]
        self.current_role = self.config["DEFAULT_ROLE"]

    @loader.command(ru_doc="–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å API –∫–ª—é—á OpenRouter")
    async def aiconfig(self, message: Message):
        """Set OpenRouter API key: .aiconfig <api_key>"""
        args = utils.get_args_raw(message)
        if not args:
            return await utils.answer(message, self.strings("no_api_key"))
        
        self.config["API_KEY"] = args
        await utils.answer(message, self.strings("api_key_set"))

    @loader.command(ru_doc="–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    async def modelist(self, message: Message):
        """Show available AI models"""
        models_text = ""
        for model_id, model_name in self.models.items():
            models_text += f"‚Ä¢ <b>{model_name}</b>\n  <code>{model_id}</code>\n\n"
        
        await utils.answer(
            message,
            self.strings("available_models").format(models_text)
        )

    @loader.command(ru_doc="–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å AI")
    async def setmodel(self, message: Message):
        """Set AI model: .setmodel <model_id>"""
        args = utils.get_args_raw(message)
        if args in self.models:
            self.current_model = args
            await utils.answer(
                message,
                self.strings("model_set").format(self.models[args])
            )
        else:
            await self.modelist(message)

    @loader.command(ru_doc="–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–æ–ª—å –¥–ª—è AI")
    async def setrole(self, message: Message):
        """Set AI role: .setrole <role description>"""
        args = utils.get_args_raw(message)
        if args:
            self.current_role = args
            await utils.answer(message, self.strings("role_set").format(args))

    @loader.command(ru_doc="–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é ")
    async def clearai(self, message: Message):
        """Clear AI chat history"""
        chat_id = str(message.chat_id)
        if chat_id in self.chat_history:
            self.chat_history[chat_id] = []
        await utils.answer(message, self.strings("history_cleared"))

    @loader.command(ru_doc="–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ AI")
    async def aiinfo(self, message: Message):
        """Show current AI settings"""
        await utils.answer(
            message,
            self.strings("current_settings").format(
                model=self.models.get(self.current_model, self.current_model),
                role=self.current_role
            )
        )

    async def _make_request(self, messages: List[Dict[str, str]]) -> str:
        """Make API request to OpenRouter"""
        if not self.config["API_KEY"]:
            return self.strings("no_api_key")

        async with aiohttp.ClientSession() as session:
            try:
                async with session.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.config['API_KEY']}",
                        "HTTP-Referer": "https://github.com/hikariatama/Hikka",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.current_model,
                        "messages": messages
                    },
                    timeout=100
                ) as response:
                    if response.status != 200:
                        return f"API Error: {response.status}"
                    
                    data = await response.json()
                    return data["choices"][0]["message"]["content"]
            except Exception as e:
                logger.exception("Error making OpenRouter request")
                return f"Error: {str(e)}"

    @loader.command(ru_doc="–û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ AI")
    async def ai(self, message: Message):
        """Send message to AI: .ai <message> or reply to message/file"""
        chat_id = str(message.chat_id)
        
        if chat_id not in self.chat_history:
            self.chat_history[chat_id] = []

        if message.is_reply:
            reply = await message.get_reply_message()
            if reply.file:
                # Handle file content
                try:
                    file_content = await reply.download_media(bytes)
                    query = file_content.decode('utf-8')
                except Exception:
                    return await utils.answer(
                        message,
                        self.strings("error_processing").format("Cannot read file content")
                    )
            else:
                query = reply.text
        else:
            query = utils.get_args_raw(message)

        if not query:
            return await utils.answer(
                message,
                self.strings("error_processing").format("No query provided")
            )

        status_message = await utils.answer(message, self.strings("processing"))

        # Prepare conversation history
        messages = [{"role": "system", "content": self.current_role}]
        messages.extend(self.chat_history[chat_id])
        messages.append({"role": "user", "content": query})

        response = await self._make_request(messages)

        if not response:
            return await utils.answer(status_message, self.strings("no_response"))

        self.chat_history[chat_id].append({"role": "user", "content": query})
        self.chat_history[chat_id].append({"role": "assistant", "content": response})

        if len(self.chat_history[chat_id]) > 20:
            self.chat_history[chat_id] = self.chat_history[chat_id][-20:]

        await utils.answer(status_message, f"ü§ñ <b>AI Response:</b>\n\n{response}")
